{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Live Demo\n",
    "\n",
    "Dans ce notebook, nous allons utiliser nos modèles afin de déterminer la nature de l'image qui se trouve devant le robot.  \n",
    "(Suivant les classes déterminées dans les fichiers précédents)  \n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Pour utiliser ce notebook il faut avoir au préalable réalisé les trois modèles :  \n",
    "- best_model.pth  \n",
    "- best_model_direction.pth  \n",
    "- best_model_vitesse.pth  \n",
    "\n",
    "Via le notebook train_model.ipynb.  \n",
    "Attention à bien vérifier que le processus est terminé dans ce précédent notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from jetbot import Robot\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filenames = ['blocked','free','stopsign','vitesses','directions','pieton']\n",
    "vitesses = ['speed1sign','speed2sign','speed3sign']\n",
    "directions = ['moveright','moveleft']\n",
    "filenames.sort()\n",
    "vitesses.sort()\n",
    "directions.sort()\n",
    "\n",
    "largeur_image = 600\n",
    "hauteur_image = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redéfinition des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, len(filenames))\n",
    "\n",
    "model_direction = torchvision.models.alexnet(pretrained=False)\n",
    "model_direction.classifier[6] = torch.nn.Linear(model_direction.classifier[6].in_features, len(directions))\n",
    "\n",
    "model_vitesse = torchvision.models.alexnet(pretrained=False)\n",
    "model_vitesse.classifier[6] = torch.nn.Linear(model_vitesse.classifier[6].in_features, len(vitesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des modèles obtenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model_direction.load_state_dict(torch.load('best_model_direction.pth'))\n",
    "model_vitesse.load_state_dict(torch.load('best_model_vitesse.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande suivante permet de transférer le poids des modèles sur le GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model_direction = model_direction.to(device)\n",
    "model_vitesse = model_vitesse.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la fonction de preprocessing\n",
    "\n",
    "Cette fonction permet de reformater les images obtenues par la caméra pour les faire correspondre au format des modèles. Nous réalisons alors la :\n",
    "\n",
    "1. Conversion de BGR à RGB\n",
    "2. Convertir de la disposition HWC à la disposition CHW\n",
    "3. Normalisation des valeurs des différents pixels\n",
    "4. Transfert des données du CPU au GPU\n",
    "5. Ajout d'une diension aux valeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "def preprocess2(x):\n",
    "    global device, normalize\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage de la caméra et des sliders  \n",
    "Les sliders vont permettre ici de donner un aperçu du résultat de l'analyse des images qui est donnée par une certitude entre 0 et 1 pour chaque issue possible.\n",
    "\n",
    "Par exemple, si la certitude du modèle que l'image en entrée est un piéton vaut 0.8 alors il y a de forte chance que ce soit le cas. Les sliders viennent donc afficher cette valeur et nous permet de \"voir\" l'interprétation du robot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b75c7f0d8bc4bbdae6d944fadff92a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ad3f15db094f829bfb057c032f0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Proba.:'), Box(children=(FloatSlider(value=0.0, description='blocked', max=1.0, or…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = Camera.instance(width=largeur_image, height=hauteur_image,fps=3)\n",
    "image = widgets.Image(format='jpeg', width=largeur_image, height=hauteur_image)\n",
    "sliders = []\n",
    "\n",
    "for name in filenames+vitesses+directions:\n",
    "    sliders.append(widgets.FloatSlider(description=name, min=0.0, max=1.0, orientation='vertical'))\n",
    "    \n",
    "speed_slider = widgets.FloatSlider(description='Speed', min=0.0, max=0.2, orientation='vertical')\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "\n",
    "box_layout = widgets.Layout(overflow='scroll hidden',\n",
    "                    border='3px solid black',\n",
    "                    width='80%',\n",
    "                    height='',\n",
    "                    flex_flow='row',\n",
    "                    display='flex')\n",
    "carousel = widgets.Box(children=sliders, layout=box_layout)\n",
    "display(widgets.VBox([image, speed_slider]))\n",
    "display(widgets.VBox([widgets.Label('Proba.:'), carousel]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du robot pour le controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions suivantes permettent de gérer les différentes situations:\n",
    "- D'abord, on détecte s'il y a un obstacle, un stop ou un piéton : si c'est le cas on arrête le robot\n",
    "- On détecte ensuite s'il y a des panneaux vitesses ou direction\n",
    "    - Si un panneau vitesse est détecté on utilise le modele_vitesse pour voir quel panneau est détecté\n",
    "    - Même chose les panneaux direction avec le modele_direction\n",
    "- sinon on considère que c'est libre et on avance  \n",
    "\n",
    "Attention, vous aurez besoin de la fonction crop disponible tout en bas avant d'executer cette portion du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cette première fonction permet de mettre en avant les objets détectés mais ne fait pas avancer le robot\n",
    "def update(change):\n",
    "    global sliders, robot\n",
    "    x = change['new'] \n",
    "    x2 = change['new']\n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "\n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    probs = []\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        probs.append(float(y.flatten()[i]))\n",
    "        sliders[i].value = probs[i]\n",
    "             \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette seconde fonction doit permettre de mettre en évidence la distinction des panneaux vitesses\n",
    "#Nous n'avons pas pu aller au bout de la démarche ici car la détection de contour n'est pas assez robuste\n",
    "\n",
    "decisions = [\"blocked\", \"directions\",\"free\",\"pieton\",\"stopsign\",\"vitesses\"]\n",
    "seuil = 0.7\n",
    "speed_coef = 1\n",
    "def save_snapshot():\n",
    "    image_path = os.path.join('analyse/', '1.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "         \n",
    "def update(change):\n",
    "    global sliders, robot, speed_coef\n",
    "    x = change['new'] \n",
    "    x2 = change['new']\n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "\n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    probs = []\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        probs.append(float(y.flatten()[i]))\n",
    "        sliders[i].value = probs[i]\n",
    "        \n",
    "\n",
    "    os.remove('analyse/1.jpg')\n",
    "    save_snapshot()\n",
    "    time.sleep(0.01)\n",
    "    crop('analyse/1.jpg','vitesse')\n",
    "    cropX = cv2.imread('analyse/1_crop.jpg')\n",
    "    time.sleep(0.01)\n",
    "        \n",
    "    xv = preprocess2(cropX)\n",
    "    v = model_vitesse(xv)\n",
    "    v = F.softmax(v, dim=1)\n",
    "    probsV = []\n",
    "    for i in range(len(vitesses)):\n",
    "        probsV.append(float(v.flatten()[i]))\n",
    "        sliders[i+len(filenames)-1].value = probsV[i]            \n",
    "        \n",
    "    if probsV[0]>seuil:\n",
    "        speed_coef = 1\n",
    "    elif probsV[1]>seuil:\n",
    "        speed_coef = 2\n",
    "    elif probsV[2]>seuil:\n",
    "        speed_coef = 3\n",
    "                    \n",
    "    else :\n",
    "        robot.forward(speed_slider.value*speed_coef)\n",
    "        \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer il suffit d'exécuter la ligne suivante.  \n",
    "ATTENTION! Le robot peut risquer de bouger, vérifiez bien l'espace disponible autour de lui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Arrêt\n",
    "Pour arrêter le processus le code suivant sera utilisé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ne plus garder la liaison vidéo (gain en bande passante), vous pouvez faire la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ligne suivante est pour rétablir la liaison vidéo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour l'arrêt complet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions permettant de recadrer les images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctionnement presque identique que dans train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def crop(path,sign):\n",
    "    \n",
    "    #image_read = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.imread(path)\n",
    "    ## conversion en couleurs hsv\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #filtrage\n",
    "    # Set minimum and max HSV values to display\n",
    "    if sign == 'vitesse':\n",
    "        lower1 = np.array([0, 150, 50])\n",
    "        upper1 = np.array([15,255, 140])\n",
    "\n",
    "        lower2 = np.array([165,90, 50])\n",
    "        upper2 = np.array([179, 255, 255])\n",
    "        # Create HSV Image and threshold into a range.\n",
    "        mask1 = cv2.inRange(hsv, lower1, upper1)\n",
    "        mask2 = cv2.inRange(hsv, lower2, upper2)\n",
    "        mask1 += mask2\n",
    "    \n",
    "    elif sign == 'direction':\n",
    "        lower1 = np.array([100, 140, 50])\n",
    "        upper1 = np.array([130, 255, 255])\n",
    "        mask1 = cv2.inRange(hsv, lower1, upper1)\n",
    "        \n",
    "    target = cv2.bitwise_and(img,img, mask=mask1)\n",
    "\n",
    "\n",
    "\n",
    "    # convert to RGB\n",
    "    image = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
    "    imge = cv2.bitwise_not(image)\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(imge, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # create a binary thresholded image\n",
    "    if sign == 'vitesse':\n",
    "        _, binary = cv2.threshold(gray, 195, 255, cv2.THRESH_BINARY_INV)\n",
    "    else: \n",
    "        _, binary = cv2.threshold(gray, 250, 250, cv2.THRESH_TOZERO_INV)\n",
    "           \n",
    "    #recherche du contour\n",
    "    contours,hierarchy=cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    #Récupération du plus grand contour :\n",
    "    indice = -1\n",
    "    max = 0\n",
    "    for i in range(len(contours)):\n",
    "        long = len(contours[i])\n",
    "        if long > max:\n",
    "            indice = i\n",
    "            max = long\n",
    "\n",
    "    contour2 = [contours[indice]]\n",
    "\n",
    "    # recadrage sur le plus grand contour:\n",
    "    x = []\n",
    "    y = []\n",
    "    for couple in contour2[0]:\n",
    "        x.append(couple[0][0])\n",
    "        y.append(couple[0][1])\n",
    "\n",
    "    xmax = -1\n",
    "    xmin = 1000\n",
    "    ymax = -1\n",
    "    ymin = 1000\n",
    "    \n",
    "    #les conditions suivantes permettent de ne pas prendre en compte le contour de l'image entière qui peut apparaitre \n",
    "    for i in x:\n",
    "        if 10 <i< 590 and i>xmax:\n",
    "            xmax = i\n",
    "\n",
    "        if 10<i< 590 and i<xmin:\n",
    "            xmin = i\n",
    "    for i in y:\n",
    "        if 10 <i< 590 and i>ymax:\n",
    "            ymax = i\n",
    "\n",
    "        if 10<i< 590 and i<ymin:\n",
    "            ymin = i   \n",
    "    \n",
    "    #Si l'image est trop petite on considère que c'est une erreur et qu'il n'y a pas de panneau sur l'image -> l'image sera alors supprimée\n",
    "    if xmax-xmin < 2 or ymax-ymin<2:\n",
    "        print(\"ok\")\n",
    "        return \"error: No image found\"\n",
    "    \n",
    "    #on vient rogner l'image en rajoutant 10 pixels sur chaque côté pour avoir une vue un peu plus large de l'objet\n",
    "    dim = (largeur_image,hauteur_image)\n",
    "    cropped_image = cv2.resize(img[ymin-10:ymax+10, xmin-10:xmax+10], dim, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite('analyse/1_crop.jpg', cropped_image)\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
