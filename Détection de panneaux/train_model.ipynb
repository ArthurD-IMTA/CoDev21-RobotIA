{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des 3 modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeur_image = 600\n",
    "hauter_image = 600\n",
    "filenames = ['blocked','free','stopsign','vitesses','directions','pieton']\n",
    "vitesses = ['speed1sign','speed2sign','speed3sign']\n",
    "directions = ['moveright','moveleft']\n",
    "filenames.sort()\n",
    "vitesses.sort()\n",
    "directions.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des bases de données\n",
    "Pour pouvoir créer les différents modèles, il faut mettre dans un dossier:\n",
    "- dataset_direction les images montrant les panneaux de directions (après rognage)\n",
    "- dataset_vitesse les images montrant les panneaux de vitesse (après rognage)  \n",
    "\n",
    "Il est important de garder la même classification dans ces dossiers: dossiers moveleft et moveright dans dataset_direction et dossiers speed1sign, speed2sign et speed3sign dans dataset_vitesse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Si besoin de dézipper : </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q dataset.zip\n",
    "!unzip -q dataset_vitesse.zip\n",
    "!unzip -q dataset_direction.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1), #ColorJitter(brightness=0, contrast=0, saturation=0, hue=0) hue = teinte\n",
    "        transforms.Resize((largeur_image, hauter_image)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "dataset_direction = datasets.ImageFolder(\n",
    "    'dataset_direction',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((largeur_image, hauter_image)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "dataset_vitesse = datasets.ImageFolder(\n",
    "    'dataset_vitesse',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((largeur_image, hauter_image)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des données\n",
    "\n",
    "La moitié des données sont utilisées pour créer le modèle et l'autre moité est utilisée pour tester le modèle et ajuster les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - len(dataset)//2, len(dataset)//2])\n",
    "train_dataset_direction, test_dataset_direction = torch.utils.data.random_split(dataset_direction, [len(dataset_direction) - len(dataset_direction)//2, len(dataset_direction)//2])\n",
    "train_dataset_vitesse, test_dataset_vitesse = torch.utils.data.random_split(dataset_vitesse, [len(dataset_vitesse) - len(dataset_vitesse)//2, len(dataset_vitesse)//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de lots pour prendre les données par paquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "train_loader_direction = torch.utils.data.DataLoader(train_dataset_direction, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_loader_direction = torch.utils.data.DataLoader(test_dataset_direction, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "train_loader_vitesse = torch.utils.data.DataLoader(train_dataset_vitesse, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_loader_vitesse = torch.utils.data.DataLoader(test_dataset_vitesse, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du modèle : réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, len(filenames)) #le dernier paramètres correspond au nombre de sortie du réseau de neurones, donc ici au nombre de dossiers\n",
    "device = torch.device('cuda') #cpu pour l'executer sur son ordinateur perso et cuda pour l'executer sur le jetbot\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_direction = models.alexnet(pretrained=True)\n",
    "model_direction.classifier[6] = torch.nn.Linear(model_direction.classifier[6].in_features, len(directions))#len(directions) correspond au nbrs de panneaux direction\n",
    "device = torch.device('cuda') \n",
    "model_direction = model_direction.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vitesse = models.alexnet(pretrained=True)\n",
    "model_vitesse.classifier[6] = torch.nn.Linear(model_vitesse.classifier[6].in_features, len(vitesses))#len(vitesses) correspond au nbrs de panneaux vitesses\n",
    "device = torch.device('cuda')\n",
    "model_vitesse = model_vitesse.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement des 3 réseaux de neurones\n",
    "\n",
    "Les trois blocs suivant permettent de créer les modèles dont nous nous servirons pour décider de la situation dans laquelle nous nous trouvons.  \n",
    "- Le permier correspond à la première décision (panneaux, piéton ...)  \n",
    "- Le second au cas où l'on a des panneaux de directions  \n",
    "- Le dernier au cas où l'on a des panneaux de vitesses  \n",
    "\n",
    "Attention !! Ces codes prennent du temps à être exécutées. Il peut être intéressant de réaliser ces calculs en local sur son ordinateur puis d'importer le fichier obtenu. D'autant plus qu'avec un grand nombre de photos, la mémoire du jetbot n'est pas toujours suffisante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30 #peut être augmenter afin de tester davantage de paramètres pour le modèle mais cela implique une augmentation significative du temps d'execution\n",
    "BEST_MODEL_PATH = 'best_model.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        #Pour faire le calcul sur un ordinateur il faut utiliser la commande suivante à la place de la précédente :\n",
    "        #torch.save(model.state_dict(), BEST_MODEL_PATH, _use_new_zipfile_serialization=False)\n",
    "        #car sinon, vous ne pourrez pas relire le modèle avec le robot\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_model_direction.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model_direction.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader_direction):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_direction(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader_direction):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_direction(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_direction))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model_direction.state_dict(), BEST_MODEL_PATH)\n",
    "        #Pour faire le calcul sur un ordinateur il faut utiliser la commande suivante à la place de la précédente :\n",
    "        #torch.save(model_direction.state_dict(), BEST_MODEL_PATH, _use_new_zipfile_serialization=False)\n",
    "        #car sinon, vous ne pourrez pas relire le modèle avec le robot\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_model_vitesse.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model_vitesse.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader_vitesse):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_vitesse(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader_vitesse):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_vitesse(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset_vitesse))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        #Pour faire le calcul sur un ordinateur il faut utiliser la commande suivante à la place de la précédente :\n",
    "        #torch.save(model_vitesse.state_dict(), BEST_MODEL_PATH, _use_new_zipfile_serialization=False)\n",
    "        #car sinon, vous ne pourrez pas relire le modèle avec le robot\n",
    "        best_accuracy = test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
